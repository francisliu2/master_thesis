{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "# import myenv\n",
    "sys.path.append('../src/features/')\n",
    "sys.path.append('../src/data/')\n",
    "import data_preprocessing_from_yahoo_finance as dp\n",
    "import myenv\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on PG\n",
      "working on AAPL\n"
     ]
    }
   ],
   "source": [
    "result_np = dp.data_preprocessing_1(ticker_list_input=['PG','AAPL'], path='../data/raw/')\n",
    "c = myenv.myenv(result_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, sess, scope, mode, env=c, reuse=tf.AUTO_REUSE, lr=0.01):\n",
    "        self.sess = sess\n",
    "        self.gamma = np.float64(0.99)\n",
    "        self.lr = lr\n",
    "        self.scope = scope\n",
    "        #############################################################\n",
    "        # Inputs\n",
    "        with tf.variable_scope(self.scope+'_inputs', reuse=reuse):\n",
    "            self.price_tensor = tf.placeholder(dtype=tf.float64,\n",
    "                              shape=[None]+env.observation_space_dimension['price_tensor'], name='price_tensor')\n",
    "            self.weight = tf.placeholder(dtype=tf.float64,\n",
    "                        shape=[None]+env.observation_space_dimension['weight'], name='weight')\n",
    "\n",
    "        with tf.variable_scope(self.scope+'_network', reuse=reuse):\n",
    "            # Conv Layers\n",
    "            conv1 = tf.layers.conv2d(inputs=self.price_tensor,\n",
    "                         filters=32,\n",
    "                         kernel_size=[100,env.observation_space_dimension['price_tensor'][-1]], # Consider all stocks at once\n",
    "                         strides=2,\n",
    "                         padding='same', name='conv1')\n",
    "            conv2 = tf.layers.conv2d(inputs=conv1,\n",
    "                         filters=24,\n",
    "                         kernel_size=[10,env.observation_space_dimension['price_tensor'][-1]],\n",
    "                         strides=2,\n",
    "                         padding='same', name='conv2')\n",
    "            F = tf.reshape(conv2, [-1,np.prod(conv2.shape[1:])], name='flattern') # Flatten\n",
    "\n",
    "            # Dense Layer\n",
    "            dense1 = tf.layers.dense(inputs=F, units=100,\n",
    "                        activation=tf.nn.relu, name='dense1')\n",
    "            dense2 = tf.layers.dense(inputs=dense1, units=50,\n",
    "                        activation=tf.nn.relu, name='dense2')\n",
    "            # Concat weight tensor\n",
    "            concat = tf.concat([dense2, self.weight], 1, name='concat')\n",
    "\n",
    "            self.dense3 = tf.layers.dense(inputs=concat, units=100,\n",
    "                        activation=tf.nn.relu, name='dense3')\n",
    "\n",
    "            self.logits = tf.layers.dense(self.dense3, units=env.action_space_dimension, name='logit')\n",
    "\n",
    "\n",
    "        with tf.variable_scope(self.scope+'_policy', reuse=reuse):\n",
    "            self.new_weight = tf.nn.softmax(self.logits, name='new_weight') # Actor output\n",
    "    \n",
    "        with tf.variable_scope(self.scope+'_value', reuse=reuse):\n",
    "            self.state_value = tf.layers.dense(inputs=self.dense3, units=1, # Critic Output\n",
    "                        activation='linear', name='state_value')\n",
    "            self.critic_train_op = tf.train.AdamOptimizer(self.lr)\n",
    "\n",
    "            \n",
    "        self.output = tf.concat([self.new_weight, self.state_value], 1)            \n",
    "\n",
    "        \n",
    "        self.actor_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.scope+'_network')+ \\\n",
    "                            tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.scope+'_output/new_weight')\n",
    "        self.critic_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.scope+'_network')+ \\\n",
    "                            tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.scope+'_output/state_value')\n",
    "        \n",
    "        self.init = tf.global_variables_initializer()   \n",
    "        self.sess.run(self.init)\n",
    "        \n",
    "    def step(self, price_tensor, weight):\n",
    "        return self.sess.run(self.output, feed_dict={self.price_tensor:price_tensor, self.weight:weight})\n",
    "        \n",
    "    def get_value(self, S):\n",
    "        return self.sess.run(self.state_value, feed_dict={self.price_tensor:S[0], self.weight:S[1]})\n",
    "  \n",
    "    def get_critic_variables(self):\n",
    "        return tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=self.scope+'_input') + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=self.scope+'_network') + \\\n",
    "        tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.scope+'_value/state_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class memory(): # https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/9_Deep_Deterministic_Policy_Gradient_DDPG/DDPG.py\n",
    "    def __init__(self, capacity, env):\n",
    "        self.capacity = capacity\n",
    "        self.env = env\n",
    "        self.pointer = 0\n",
    "        dim = 1+1+1+1# S,A,R,S_\n",
    "        self.data = np.zeros(([capacity]+[dim])) # state, action, reward, next_state\n",
    "\n",
    "    def store_transition(self, state_number, action_number, r, next_state_number):\n",
    "        transition = [state_number, action_number, r, next_state_number]\n",
    "        index = self.pointer % self.capacity\n",
    "        self.data[index, :] = transition\n",
    "        self.pointer += 1\n",
    "        \n",
    "    def sample(self, n):\n",
    "        assert self.pointer >= self.capacity, 'Please fill the memory'\n",
    "        indices = np.random.choice(self.capacity, size = n)\n",
    "        sampled_data = self.data[indices, :]\n",
    "        \n",
    "        S=[]\n",
    "        A=[]\n",
    "        R=[]\n",
    "        S_=[]\n",
    "        for row in sampled_data:\n",
    "            s = [self.env.all_prices_normalized[:,int(row[0]):int(row[0]+self.env.price_window),:], self.env.weights[int(row[0])] ]\n",
    "            S.append(s) # current step -1\n",
    "            A.append(self.env.weights[int(row[1]-1)])\n",
    "            R.append(row[2])\n",
    "            s_ = [self.env.all_prices_normalized[:,int(row[3]):int(row[3]+self.env.price_window),:], self.env.weights[int(row[3])] ]\n",
    "            S_.append(s_)\n",
    "        \n",
    "        S = np.array(S)\n",
    "        S_ = np.array(S_)\n",
    "        \n",
    "        result_S = [np.stack(S[:,0], axis=0), np.stack(S[:,1], axis=0)]\n",
    "        result_A = A\n",
    "        result_R = R\n",
    "        result_S_ = [np.stack(S_[:,0], axis=0), np.stack(S_[:,1], axis=0)]\n",
    "        return result_S, result_A, result_R, result_S_\n",
    "#         return S,A,R,S_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py:1645: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  7%|▋         | 7/100 [00:00<00:01, 66.85it/s]\n",
      " 14%|█▍        | 14/100 [00:00<00:01, 67.22it/s]\n",
      " 22%|██▏       | 22/100 [00:00<00:01, 68.67it/s]\n",
      " 30%|███       | 30/100 [00:00<00:00, 70.95it/s]\n",
      " 39%|███▉      | 39/100 [00:00<00:00, 73.95it/s]\n",
      " 47%|████▋     | 47/100 [00:00<00:00, 75.51it/s]\n",
      " 56%|█████▌    | 56/100 [00:00<00:00, 77.75it/s]\n",
      " 65%|██████▌   | 65/100 [00:00<00:00, 79.61it/s]\n",
      " 74%|███████▍  | 74/100 [00:00<00:00, 80.54it/s]\n",
      " 83%|████████▎ | 83/100 [00:01<00:00, 81.43it/s]\n",
      " 92%|█████████▏| 92/100 [00:01<00:00, 80.01it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 79.45it/s]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "price_tensor, weight,_,done = c.reset()\n",
    "sess = tf.InteractiveSession()\n",
    "a = Agent(scope='worker', mode='testing', sess=sess)\n",
    "sess.run(a.init)\n",
    "M = memory(capacity=50, env=c)\n",
    "for i in tqdm(range(c.total_steps)):\n",
    "#     if done: print(i)\n",
    "#     print(c.current_step)\n",
    "    S_number = c.current_step\n",
    "#     sess.run(a.init)\n",
    "#     agent_output = sess.run(a.build_policy(), \n",
    "#                       feed_dict={a.price_tensor:[price_tensor], \n",
    "#                                  a.weight:[weight]})\n",
    "    agent_output = a.step([price_tensor], [weight])\n",
    "    env_output = c.step(agent_output[0][:-1])\n",
    "    price_tensor = env_output[0]\n",
    "    weight = env_output[1]\n",
    "    reward = env_output[2]\n",
    "    done = env_output[3]\n",
    "    M.store_transition(S_number, S_number, reward, S_number+1)\n",
    "\n",
    "S,A,R,S_ = M.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = Agent(scope='master', mode='testing', sess=sess)\n",
    "state_value_target_op = master.state_value\n",
    "state_value_target_op = R +  tf.multiply(np.float64(.99), state_value_target_op)\n",
    "state_value_target = state_value_target_op\n",
    "\n",
    "state_value_op = a.state_value\n",
    "state_value = state_value_op\n",
    "temporal_difference = tf.subtract(state_value_target, state_value, name='TD_error')\n",
    "\n",
    "# with tf.variable_scope('critic_loss', reuse=True):\n",
    "critic_loss = tf.reduce_mean(tf.square(temporal_difference))\n",
    "train_op = a.critic_train_op.minimize(critic_loss, var_list=a.get_critic_variables())\n",
    "sess.run(train_op, feed_dict={a.price_tensor:S[0], a.weight:S[1], master.price_tensor:S_[0], master.weight:S_[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428.34829560486673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1/100 [00:00<01:25,  1.15it/s]\n",
      "  2%|▏         | 2/100 [00:01<01:18,  1.25it/s]\n",
      "  3%|▎         | 3/100 [00:02<01:13,  1.32it/s]\n",
      "  4%|▍         | 4/100 [00:02<01:09,  1.38it/s]\n",
      "  5%|▌         | 5/100 [00:03<01:06,  1.43it/s]\n",
      "  6%|▌         | 6/100 [00:04<01:04,  1.46it/s]\n",
      "  7%|▋         | 7/100 [00:04<01:02,  1.49it/s]\n",
      "  8%|▊         | 8/100 [00:05<01:01,  1.50it/s]\n",
      "  9%|▉         | 9/100 [00:06<01:00,  1.51it/s]\n",
      " 10%|█         | 10/100 [00:06<00:59,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4269.336867107014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 11/100 [00:07<01:02,  1.42it/s]\n",
      " 12%|█▏        | 12/100 [00:08<01:00,  1.46it/s]\n",
      " 13%|█▎        | 13/100 [00:08<00:58,  1.48it/s]\n",
      " 14%|█▍        | 14/100 [00:09<00:57,  1.50it/s]\n",
      " 15%|█▌        | 15/100 [00:10<00:56,  1.51it/s]\n",
      " 16%|█▌        | 16/100 [00:10<00:55,  1.52it/s]\n",
      " 17%|█▋        | 17/100 [00:11<00:54,  1.52it/s]\n",
      " 18%|█▊        | 18/100 [00:12<00:53,  1.53it/s]\n",
      " 19%|█▉        | 19/100 [00:12<00:52,  1.53it/s]\n",
      " 20%|██        | 20/100 [00:13<00:52,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10157.697338259095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██        | 21/100 [00:14<00:55,  1.42it/s]\n",
      " 22%|██▏       | 22/100 [00:14<00:53,  1.46it/s]\n",
      " 23%|██▎       | 23/100 [00:15<00:52,  1.48it/s]\n",
      " 24%|██▍       | 24/100 [00:16<00:50,  1.50it/s]\n",
      " 25%|██▌       | 25/100 [00:16<00:49,  1.51it/s]\n",
      " 26%|██▌       | 26/100 [00:17<00:48,  1.52it/s]\n",
      " 27%|██▋       | 27/100 [00:18<00:47,  1.53it/s]\n",
      " 28%|██▊       | 28/100 [00:18<00:46,  1.53it/s]\n",
      " 29%|██▉       | 29/100 [00:19<00:46,  1.53it/s]\n",
      " 30%|███       | 30/100 [00:20<00:45,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117.76294262828598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███       | 31/100 [00:20<00:48,  1.43it/s]\n",
      " 32%|███▏      | 32/100 [00:21<00:46,  1.46it/s]\n",
      " 33%|███▎      | 33/100 [00:22<00:45,  1.49it/s]\n",
      " 34%|███▍      | 34/100 [00:22<00:43,  1.50it/s]\n",
      " 35%|███▌      | 35/100 [00:23<00:42,  1.51it/s]\n",
      " 36%|███▌      | 36/100 [00:24<00:42,  1.52it/s]\n",
      " 37%|███▋      | 37/100 [00:24<00:41,  1.53it/s]\n",
      " 38%|███▊      | 38/100 [00:25<00:40,  1.53it/s]\n",
      " 39%|███▉      | 39/100 [00:26<00:39,  1.53it/s]\n",
      " 40%|████      | 40/100 [00:26<00:39,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009856481688853005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 41%|████      | 41/100 [00:27<00:41,  1.43it/s]\n",
      " 42%|████▏     | 42/100 [00:28<00:39,  1.47it/s]\n",
      " 43%|████▎     | 43/100 [00:28<00:38,  1.49it/s]\n",
      " 44%|████▍     | 44/100 [00:29<00:37,  1.50it/s]\n",
      " 45%|████▌     | 45/100 [00:30<00:36,  1.52it/s]\n",
      " 46%|████▌     | 46/100 [00:30<00:35,  1.53it/s]\n",
      " 47%|████▋     | 47/100 [00:31<00:34,  1.53it/s]\n",
      " 48%|████▊     | 48/100 [00:32<00:34,  1.52it/s]\n",
      " 49%|████▉     | 49/100 [00:32<00:33,  1.53it/s]\n",
      " 50%|█████     | 50/100 [00:33<00:32,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.60195806166576e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 51%|█████     | 51/100 [00:34<00:34,  1.43it/s]\n",
      " 52%|█████▏    | 52/100 [00:34<00:32,  1.46it/s]\n",
      " 53%|█████▎    | 53/100 [00:35<00:31,  1.49it/s]\n",
      " 54%|█████▍    | 54/100 [00:36<00:30,  1.50it/s]\n",
      " 55%|█████▌    | 55/100 [00:36<00:29,  1.51it/s]\n",
      " 56%|█████▌    | 56/100 [00:37<00:29,  1.52it/s]\n",
      " 57%|█████▋    | 57/100 [00:38<00:28,  1.52it/s]\n",
      " 58%|█████▊    | 58/100 [00:38<00:27,  1.52it/s]\n",
      " 59%|█████▉    | 59/100 [00:39<00:26,  1.52it/s]\n",
      " 60%|██████    | 60/100 [00:39<00:26,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0109791538114713e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 61%|██████    | 61/100 [00:40<00:27,  1.42it/s]\n",
      " 62%|██████▏   | 62/100 [00:41<00:26,  1.46it/s]\n",
      " 63%|██████▎   | 63/100 [00:42<00:25,  1.48it/s]\n",
      " 64%|██████▍   | 64/100 [00:42<00:24,  1.50it/s]\n",
      " 65%|██████▌   | 65/100 [00:43<00:23,  1.50it/s]\n",
      " 66%|██████▌   | 66/100 [00:44<00:22,  1.51it/s]\n",
      " 67%|██████▋   | 67/100 [00:44<00:21,  1.52it/s]\n",
      " 68%|██████▊   | 68/100 [00:45<00:20,  1.53it/s]\n",
      " 69%|██████▉   | 69/100 [00:46<00:20,  1.53it/s]\n",
      " 70%|███████   | 70/100 [00:46<00:19,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.872751391817166e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|███████   | 71/100 [00:47<00:20,  1.43it/s]\n",
      " 72%|███████▏  | 72/100 [00:48<00:19,  1.47it/s]\n",
      " 73%|███████▎  | 73/100 [00:48<00:18,  1.49it/s]\n",
      " 74%|███████▍  | 74/100 [00:49<00:17,  1.50it/s]\n",
      " 75%|███████▌  | 75/100 [00:50<00:16,  1.51it/s]\n",
      " 76%|███████▌  | 76/100 [00:50<00:15,  1.52it/s]\n",
      " 77%|███████▋  | 77/100 [00:51<00:15,  1.52it/s]\n",
      " 78%|███████▊  | 78/100 [00:52<00:14,  1.53it/s]\n",
      " 79%|███████▉  | 79/100 [00:52<00:13,  1.53it/s]\n",
      " 80%|████████  | 80/100 [00:53<00:13,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.37873152427276e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 81%|████████  | 81/100 [00:54<00:13,  1.42it/s]\n",
      " 82%|████████▏ | 82/100 [00:54<00:12,  1.46it/s]\n",
      " 83%|████████▎ | 83/100 [00:55<00:11,  1.48it/s]\n",
      " 84%|████████▍ | 84/100 [00:56<00:10,  1.50it/s]\n",
      " 85%|████████▌ | 85/100 [00:56<00:09,  1.51it/s]\n",
      " 86%|████████▌ | 86/100 [00:57<00:09,  1.52it/s]\n",
      " 87%|████████▋ | 87/100 [00:58<00:08,  1.52it/s]\n",
      " 88%|████████▊ | 88/100 [00:58<00:07,  1.53it/s]\n",
      " 89%|████████▉ | 89/100 [00:59<00:07,  1.53it/s]\n",
      " 90%|█████████ | 90/100 [00:59<00:06,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.655081439651455e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 91%|█████████ | 91/100 [01:00<00:06,  1.43it/s]\n",
      " 92%|█████████▏| 92/100 [01:01<00:05,  1.46it/s]\n",
      " 93%|█████████▎| 93/100 [01:02<00:04,  1.48it/s]\n",
      " 94%|█████████▍| 94/100 [01:02<00:04,  1.50it/s]\n",
      " 95%|█████████▌| 95/100 [01:03<00:03,  1.51it/s]\n",
      " 96%|█████████▌| 96/100 [01:04<00:02,  1.51it/s]\n",
      " 97%|█████████▋| 97/100 [01:04<00:01,  1.52it/s]\n",
      " 98%|█████████▊| 98/100 [01:05<00:01,  1.53it/s]\n",
      " 99%|█████████▉| 99/100 [01:06<00:00,  1.53it/s]\n",
      "100%|██████████| 100/100 [01:06<00:00,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "S_t,A_t,R_t,S__t = M.sample(10)\n",
    "for i in tqdm(range(100)):\n",
    "    S,A,R,S_ = M.sample(20)\n",
    "    sess.run(train_op, feed_dict={a.price_tensor:S[0], a.weight:S[1], master.price_tensor:S_[0], master.weight:S_[1]})\n",
    "    if i % 10 == 0:\n",
    "        print(sess.run(critic_loss, feed_dict={a.price_tensor:S_t[0], a.weight:S_t[1], master.price_tensor:S__t[0], master.weight:S__t[1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00549842,  0.01099684,  0.01034081,  0.01616295,  0.01657702,\n",
       "        0.01995032,  0.01744778,  0.02326992,  0.01972426,  0.015901  ,\n",
       "        0.00373322,  0.00476779,  0.00122213,  0.00066501, -0.0007244 ,\n",
       "       -0.00085074, -0.0002228 ,  0.00051793,  0.00560386,  0.0017806 ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.gradients(ys=loss,xs=a.critic_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean((sum(a.get_value(S_)) + R - sum(a.get_value(S)))**2)\n",
    "tf.train.AdadeltaOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"<tf.Variable 'network/conv1/kernel:0' shape=(100, 3, 3, 32) dtype=float64_ref>\", \n",
    " \"<tf.Variable 'network/conv1/bias:0' shape=(32,) dtype=float64_ref>\",\n",
    " \"<tf.Variable 'network/conv2/kernel:0' shape=(10, 3, 32, 24) dtype=float64_ref>\",\n",
    " \"<tf.Variable 'network/conv2/bias:0' shape=(24,) dtype=float64_ref>\",\n",
    " \"<tf.Variable 'network/dense/kernel:0' shape=(14520, 100) dtype=float64_ref>\", \n",
    " \"<tf.Variable 'network/dense/bias:0' shape=(100,) dtype=float64_ref>\",\n",
    " \"<tf.Variable 'network/dense_1/kernel:0' shape=(100, 50) dtype=float64_ref>\",\n",
    " \"<tf.Variable 'network/dense_1/bias:0' shape=(50,) dtype=float64_ref>\",\n",
    " \"<tf.Variable 'network/dense_2/kernel:0' shape=(53, 100) dtype=float64_ref>\",\n",
    " \"<tf.Variable 'network/dense_2/bias:0' shape=(100,) dtype=float64_ref>\",\n",
    " \"<tf.Variable 'network/dense_3/kernel:0' shape=(100, 3) dtype=float64_ref>\",\n",
    " \"<tf.Variable 'network/dense_3/bias:0' shape=(3,) dtype=float64_ref>\",\n",
    " \"<tf.Variable 'value/state_value/kernel:0' shape=(100, 1) dtype=float64_ref>\",\n",
    " \"<tf.Variable 'value/state_value/bias:0' shape=(1,) dtype=float64_ref>\",\n",
    " \"<tf.Variable 'Variable:0' shape=(10, 1) dtype=float64_ref>\", \n",
    " \"<tf.Variable 'Variable_1:0' shape=(10, 1) dtype=float64_ref>\"] \n",
    "loss Tensor(\"Mean_3:0\", shape=(), dtype=float64).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    t = a.train_critic(sess, S, A, R, S_)\n",
    "    sess.run(t, feed_dict={a.price_tensor:S[0], a.weight:S[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_tensor = tf.placeholder(dtype=tf.float64,\n",
    "                  shape=[None]+c.observation_space_dimension['price_tensor'], name='price_tensor')\n",
    "weight = tf.placeholder(dtype=tf.float64,\n",
    "            shape=[None]+c.observation_space_dimension['weight'], name='weight')\n",
    "\n",
    "next_state_value_ph = tf.placeholder(tf.float64, shape=[None,1])\n",
    "r_ph = tf.placeholder(tf.float64, shape=[None, 1])\n",
    "\n",
    "td_error = tf.reduce_mean(r_ph + 0.99*next_state_value_ph - a.state_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "state_value = tf.placeholder(tf.float64, [1,1])\n",
    "R_ph = tf.placeholder(tf.float64, [None, ])  \n",
    "next_state_value_ph = tf.placeholder(tf.float64, [None, ])      \n",
    "next_state_value = sess.run(a.state_value, feed_dict={a.price_tensor:S_[0], a.weight:S_[1]}) \n",
    "        \n",
    "td_error = tf.reduce_mean(R_ph + .99*next_state_value_ph - state_value)\n",
    "critic_loss = tf.square(td_error)\n",
    "        \n",
    "critic_train_op = tf.train.AdamOptimizer(0.01).minimize(critic_loss)\n",
    "        \n",
    "sess.run(critic_train_op, feed_dict={a.price_tensor:S[0],\n",
    "                                             a.weight:S[1], \n",
    "                                             R_ph:R,\n",
    "                                             next_state_value_ph:next_state_value})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S,A,R,S_ = M.sample(10)\n",
    "a.train_critic(sess,S,A,R,S_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_tensor, weight,_,done = c.reset()\n",
    "sess = tf.Session()\n",
    "a = Agent(name='testing', mode='testing')\n",
    "M = memory(capacity=50, env=c)\n",
    "\n",
    "S_list = []\n",
    "R_list = []\n",
    "next_S_list= []\n",
    "for i in tqdm(range(c.total_steps)):\n",
    "    S_list.append(price_tensor)\n",
    "#     if done: print(i)\n",
    "#     print(c.current_step)\n",
    "    sess.run(a.init)\n",
    "    agent_output = sess.run(a.output, \n",
    "                      feed_dict={a.price_tensor:[price_tensor], \n",
    "                                 a.weight:[weight]})\n",
    "    env_output = c.step(agent_output[0][:-1])\n",
    "    price_tensor = env_output[0]\n",
    "    weight = env_output[1]\n",
    "    reward = env_output[2]\n",
    "    done = env_output[3]\n",
    "    R_list.append(reward)\n",
    "    next_S_list.append(price_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs --> Critic --> state_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.multiply(R,a.gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
